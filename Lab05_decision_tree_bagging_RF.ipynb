{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ellinei/229352-StatisticalLearning/blob/main/Lab05_decision_tree_bagging_RF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTGPQunUMe9n"
      },
      "source": [
        "### Statistical Learning for Data Science 2 (229352)\n",
        "#### Instructor: Donlapark Ponnoprat\n",
        "\n",
        "#### [Course website](https://donlapark.pages.dev/229352/)\n",
        "\n",
        "## Lab #5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_YkUVk-Me9r"
      },
      "source": [
        "#### Load data at: https://donlapark.pages.dev/229352/heart_disease.csv\n",
        "\n",
        "* Decision tree ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html))\n",
        "* Random hyperparameter search using cross-validation ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tShvCHLSAsu6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import graphviz\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "\n",
        "# import data\n",
        "data = pd.read_csv(\"heart_disease.csv\", na_values=\"?\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_AisL0BMe9w"
      },
      "outputs": [],
      "source": [
        "\n",
        "# split into X and y\n",
        "y = data[\"label\"]\n",
        "X = data.drop(\"label\", axis=1)\n",
        "\n",
        "# split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# impute missing values\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# Create a decision tree\n",
        "clf = DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmE7nqYPEy-G"
      },
      "source": [
        "![5CV](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRlxCcrvBN9S"
      },
      "outputs": [],
      "source": [
        "params = {'max_depth': [3, 6, 9, 12]}\n",
        "\n",
        "gridcv = GridSearchCV(clf, params, scoring='accuracy', cv=5)\n",
        "gridcv.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCd-8EFBBR5F"
      },
      "outputs": [],
      "source": [
        "gridcv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv4yI-fYBSBM"
      },
      "outputs": [],
      "source": [
        "plot_data = export_graphviz(gridcv.best_estimator_,\n",
        "                            out_file=None,\n",
        "                            filled=True,\n",
        "                            rounded=True,\n",
        "                            feature_names=data.columns[:-1],\n",
        "                            class_names=['0', '1'])\n",
        "\n",
        "graph = graphviz.Source(plot_data)\n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagged decision trees\n",
        "* Bagging classifier ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html))"
      ],
      "metadata": {
        "id": "bpMaSjmBPfJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "6_NDqbkzPImm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random forest classifier\n",
        "* Random forest ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html))"
      ],
      "metadata": {
        "id": "xnCpla0JQqNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "wBZHX4af1H5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtcscwZPBRJ2"
      },
      "source": [
        "#### Exercise\n",
        "1. Study the hyperparameters of three models: [Decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), [Bagged Decision Trees](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) and [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
        "2. For each model, use pipeline+grid search cross-validation across multiple hyperparameters to find the best model.\n",
        "* Decision tree: choose at least 3 hyperparameters\n",
        "* Bagged decision trees: choose at least 3 hyperparameters\n",
        "* Random forest: choose at least 3 hyperparameters\n",
        "3. For each model, compute the `f1_macro` and `accuracy` score on the test set.\n",
        "* What is your best model?\n",
        "* Plot the best tree model\n",
        "* What hyperparameters did you choose? (explain in words, not in `sklearn's` parameter name)\n",
        "* What are the best values of your hyperparameters?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f399f2f9"
      },
      "source": [
        "dt_pipeline = Pipeline([\n",
        "    ('imputer', imputer),\n",
        "    ('decisiontreeclassifier', DecisionTreeClassifier())\n",
        "])\n",
        "\n",
        "dt_params = {\n",
        "    'decisiontreeclassifier__max_depth': [3, 6, 9, 12],\n",
        "    'decisiontreeclassifier__min_samples_split': [2, 5, 10],\n",
        "    'decisiontreeclassifier__min_samples_leaf': [1, 2, 4]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bagging_pipeline = Pipeline([\n",
        "    ('imputer', imputer),\n",
        "    ('baggingclassifier', BaggingClassifier(estimator=DecisionTreeClassifier()))\n",
        "])\n",
        "\n",
        "bagging_params = {\n",
        "    'baggingclassifier__n_estimators': [10, 50, 100],\n",
        "    'baggingclassifier__max_samples': [0.5, 0.7, 1.0],\n",
        "    'baggingclassifier__max_features': [0.5, 0.7, 1.0]\n",
        "}\n"
      ],
      "metadata": {
        "id": "OPYqBIT6IcU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_pipeline = Pipeline([\n",
        "    ('imputer', imputer),\n",
        "    ('randomforestclassifier', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "rf_params = {\n",
        "    'randomforestclassifier__n_estimators': [10, 50, 100],\n",
        "    'randomforestclassifier__max_depth': [3, 6, 9, 12],\n",
        "    'randomforestclassifier__min_samples_leaf': [1, 2, 4]\n",
        "}"
      ],
      "metadata": {
        "id": "lQOnuioBIcKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd469aa3"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
        "\n",
        "scoring = {\n",
        "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
        "    'accuracy': make_scorer(accuracy_score)\n",
        "}\n",
        "\n",
        "dt_grid_search = GridSearchCV(dt_pipeline, dt_params, scoring=scoring, refit='f1_macro', cv=5)\n",
        "dt_grid_search.fit(X_train, y_train)\n",
        "\n",
        "bagging_grid_search = GridSearchCV(bagging_pipeline, bagging_params, scoring=scoring, refit='f1_macro', cv=5)\n",
        "bagging_grid_search.fit(X_train, y_train)\n",
        "\n",
        "rf_grid_search = GridSearchCV(rf_pipeline, rf_params, scoring=scoring, refit='f1_macro', cv=5)\n",
        "rf_grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYuP6DXhY9Xr"
      },
      "source": [
        "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
        "\n",
        "scoring = {\n",
        "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
        "    'accuracy': make_scorer(accuracy_score)\n",
        "}\n",
        "\n",
        "dt_grid_search = GridSearchCV(dt_pipeline, dt_params, scoring=scoring, refit='f1_macro', cv=5)\n",
        "dt_grid_search.fit(X_train, y_train)\n",
        "\n",
        "bagging_grid_search = GridSearchCV(bagging_pipeline, bagging_params, scoring=scoring, refit='f1_macro', cv=5)\n",
        "bagging_grid_search.fit(X_train, y_train)\n",
        "\n",
        "rf_grid_search = GridSearchCV(rf_pipeline, rf_params, scoring=scoring, refit='f1_macro', cv=5)\n",
        "rf_grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7c2aeda"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cee814f"
      },
      "source": [
        "best_dt = dt_grid_search.best_estimator_\n",
        "best_bagging = bagging_grid_search.best_estimator_\n",
        "best_rf = rf_grid_search.best_estimator_\n",
        "\n",
        "dt_pred = best_dt.predict(X_test)\n",
        "bagging_pred = best_bagging.predict(X_test)\n",
        "rf_pred = best_rf.predict(X_test)\n",
        "\n",
        "dt_f1 = f1_score(y_test, dt_pred, average='macro')\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "\n",
        "bagging_f1 = f1_score(y_test, bagging_pred, average='macro')\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
        "\n",
        "rf_f1 = f1_score(y_test, rf_pred, average='macro')\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "print(f\"Decision Tree - F1 Macro: {dt_f1:.4f}, Accuracy: {dt_accuracy:.4f}\")\n",
        "print(f\"Bagging - F1 Macro: {bagging_f1:.4f}, Accuracy: {bagging_accuracy:.4f}\")\n",
        "print(f\"Random Forest - F1 Macro: {rf_f1:.4f}, Accuracy: {rf_accuracy:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc2e8fba"
      },
      "source": [
        "print(\"\\n--- Model Comparison ---\")\n",
        "print(f\"Decision Tree - F1 Macro: {dt_f1:.4f}, Accuracy: {dt_accuracy:.4f}\")\n",
        "print(f\"Bagging - F1 Macro: {bagging_f1:.4f}, Accuracy: {bagging_accuracy:.4f}\")\n",
        "print(f\"Random Forest - F1 Macro: {rf_f1:.4f}, Accuracy: {rf_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nBest Model\")\n",
        "if rf_f1 > dt_f1 and rf_f1 > bagging_f1:\n",
        "    best_model = \"Random Forest\"\n",
        "elif dt_f1 > rf_f1 and dt_f1 > bagging_f1:\n",
        "    best_model = \"Decision Tree\"\n",
        "else:\n",
        "    best_model = \"Bagging\"\n",
        "\n",
        "print(best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a01bde05"
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "best_dt_classifier = best_dt.named_steps['decisiontreeclassifier']\n",
        "\n",
        "plot_data = export_graphviz(best_dt_classifier,\n",
        "                                out_file=None,\n",
        "                                filled=True,\n",
        "                                rounded=True,\n",
        "                                feature_names=data.columns[:-1],\n",
        "                                class_names=['0', '1'])\n",
        "\n",
        "graph = graphviz.Source(plot_data)\n",
        "display(graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "942e5d18"
      },
      "source": [
        "print(\"\\nBest hyperparameters for Decision Tree:\")\n",
        "print(dt_grid_search.best_params_)\n",
        "\n",
        "print(\"\\nBest hyperparameters for Bagging Classifier:\")\n",
        "print(bagging_grid_search.best_params_)\n",
        "\n",
        "print(\"\\nBest hyperparameters for Random Forest:\")\n",
        "print(rf_grid_search.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27068ff3"
      },
      "source": [
        "**Decision Tree:**\n",
        "\n",
        "*   **Maximum depth (ความลึกสูงสุด):** ควบคุมความลึกของต้นไม้ ค่าที่ดีที่สุดคือ `3`\n",
        "*   **Minimum samples to split (จำนวนตัวอย่างขั้นต่ำในการแบ่ง):** จำนวนตัวอย่างขั้นต่ำที่จำเป็นในการแยกโหนด ค่าที่ดีที่สุดคือ `5`\n",
        "*   **Minimum samples per leaf (จำนวนตัวอย่างขั้นต่ำต่อใบ):** จำนวนตัวอย่างขั้นต่ำที่ต้องมีในโหนดใบ ค่าที่ดีที่สุดคือ `2`\n",
        "\n",
        "**Bagging Classifier:**\n",
        "\n",
        "*   **Number of estimators (จำนวนโมเดลย่อย):** จำนวนโมเดล Decision Tree ใน Bagging ensemble ค่าที่ดีที่สุดคือ `100`\n",
        "*   **Maximum samples (สัดส่วนตัวอย่างในการสุ่มเลือก):** สัดส่วนของตัวอย่างจาก Training set ที่ใช้ในการฝึกแต่ละโมเดลย่อย ค่าที่ดีที่สุดคือ `0.5`\n",
        "*   **Maximum features (สัดส่วนของคุณสมบัติในการสุ่มเลือก):** สัดส่วนของคุณสมบัติจาก Feature set ที่ใช้ในการฝึกแต่ละโมเดลย่อย ค่าที่ดีที่สุดคือ `0.5`\n",
        "\n",
        "**Random Forest:**\n",
        "\n",
        "*   **Number of estimators (จำนวนต้นไม้ในป่าสุ่ม):** จำนวนต้นไม้ Decision Tree ใน Random Forest ค่าที่ดีที่สุดคือ `100`\n",
        "*   **Maximum depth (ความลึกสูงสุดของต้นไม้):** ควบคุมความลึกสูงสุดของแต่ละต้นไม้ในป่าสุ่ม ค่าที่ดีที่สุดคือ `9`\n",
        "*   **Minimum samples per leaf (จำนวนตัวอย่างขั้นต่ำต่อใบ):** จำนวนตัวอย่างขั้นต่ำที่ต้องมีในโหนดใบของแต่ละต้นไม้ ค่าที่ดีที่สุดคือ `4`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}