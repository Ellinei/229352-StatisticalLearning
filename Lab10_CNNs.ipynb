{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ellinei/229352-StatisticalLearning/blob/main/Lab10_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical Learning for Data Science 2 (229352)\n",
        "#### Instructor: Donlapark Ponnoprat\n",
        "\n",
        "#### [Course website](https://donlapark.pages.dev/229352/)\n",
        "\n",
        "## Lab #10"
      ],
      "metadata": {
        "id": "R3EHk_vLhxDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision # For utils.make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm # For nice progress bars\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Set device to GPU if available, else CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "t-jV4RoaQjuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a dataset of pizza, stead and sushi images ([source](https://donlapark.pages.dev/229352/pizza_steak_sushi.zip))"
      ],
      "metadata": {
        "id": "65iWpYjuo1b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q pizza_steak_sushi.zip"
      ],
      "metadata": {
        "id": "pkoZPKjOcixg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data augmentation\n",
        "\n",
        "![augmentation](https://miro.medium.com/max/700/0*LR1ZQucYW96prDte)\n",
        "\n",
        "See more transformations in [Pytorch documentation](https://docs.pytorch.org/vision/stable/transforms.html#v2-api-reference-recommended)"
      ],
      "metadata": {
        "id": "lGMVh81YgMTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define data transformations\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Resize all images to 224x224\n",
        "    transforms.ToTensor(),         # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # Normalize pixel values (ImageNet statistics)\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "    transforms.RandomHorizontalFlip(0.4)\n",
        "])\n",
        "\n",
        "# 2. Create datasets using ImageFolder\n",
        "train_data = datasets.ImageFolder(root=\"train\",\n",
        "                                  transform=data_transforms) # Write your code here\n",
        "test_data = datasets.ImageFolder(root=\"test\",\n",
        "                                 transform=data_transforms) # Write your code here\n",
        "\n",
        "# Get class names and their mapping\n",
        "class_names = train_data.classes\n",
        "class_to_idx = train_data.class_to_idx\n",
        "\n",
        "print(f\"Class names: {class_names}\")\n",
        "print(f\"Class to index mapping: {class_to_idx}\")\n",
        "print(f\"Number of training samples: {len(train_data)}\")\n",
        "print(f\"Number of testing samples: {len(test_data)}\")\n",
        "\n",
        "# 3. Create DataLoaders\n",
        "BATCH_SIZE = 32 # You can experiment with different batch sizes\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=32,\n",
        "                              shuffle=True)  # Write your code here\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=len(test_data),\n",
        "                             shuffle=False)  # Write your code here\n",
        "\n",
        "print(f\"Number of batches in training DataLoader: {len(train_dataloader)}\")\n",
        "print(f\"Number of batches in testing DataLoader: {len(test_dataloader)}\")\n",
        "\n",
        "# Let's visualize a sample image and its label\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0)) # Convert from (C, H, W) to (H, W, C)\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean # Undo normalization\n",
        "    inp = np.clip(inp, 0, 1) # Clip pixel values to [0, 1]\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(train_dataloader))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs[:4]) # Show first 4 images\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "imshow(out, title=[class_names[x] for x in classes[:4]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_CXgPlr4Vt2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Implement and Train LeNet\n",
        "\n",
        "LeNet-5 is one of the earliest convolutional neural networks, developed by Yann LeCun et al. in the 1990s. While originally designed for smaller images (like MNIST digits), we will adapt its architecture for our 224x224 pixel images.\n",
        "\n",
        "![lenet5](http://d2l.ai/_images/lenet.svg)\n",
        "\n",
        "### LeNet Architecture (Adapted for 224x224 input, 3 output classes):\n",
        "\n",
        "1.  **Input Layer**: 3x224x224 image (RGB channels).\n",
        "2.  **Conv1**: ([Conv2d document](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html))\n",
        "    *   Input Channels: 3\n",
        "    *   Output Channels: 6\n",
        "    *   Kernel Size: 5x5\n",
        "    *   Stride: 1\n",
        "    *   Activation: ReLU\n",
        "3.  **Pool1**: ([MaxPool2d document](https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html))\n",
        "    *   Type: Max Pooling\n",
        "    *   Kernel Size: 2x2\n",
        "    *   Stride: 2\n",
        "4.  **Conv2**:\n",
        "    *   Input Channels: 6\n",
        "    *   Output Channels: 16\n",
        "    *   Kernel Size: 5x5\n",
        "    *   Stride: 1\n",
        "    *   Activation: ReLU\n",
        "5.  **Pool2**:\n",
        "    *   Type: Max Pooling\n",
        "    *   Kernel Size: 2x2\n",
        "    *   Stride: 2\n",
        "6.  **Flatten**: Flatten the 3D feature maps into a 1D vector.\n",
        "    *   *Hint*: After Pool2, the feature map size will be `16 * (something) * (something)`. You'll need to calculate this dimension based on the input size and the conv/pool operations.\n",
        "        *   Input (224x224) -> Conv1 (224-5+1 = 220x220)\n",
        "        *   Pool1 (220/2 = 110x110)\n",
        "        *   Conv2 (110-5+1 = 106x106)\n",
        "        *   Pool2 (106/2 = 53x53)\n",
        "        *   So, the output of Pool2 will be `16 * 53 * 53`.\n",
        "7.  **FC1 (Fully Connected 1)**:\n",
        "    *   Input Features: `16 * 53 * 53`\n",
        "    *   Output Features: 120\n",
        "    *   Activation: ReLU\n",
        "8.  **FC2 (Fully Connected 2)**:\n",
        "    *   Input Features: 120\n",
        "    *   Output Features: 84\n",
        "    *   Activation: ReLU\n",
        "9.  **Output Layer (FC3)**:\n",
        "    *   Input Features: 84\n",
        "    *   Output Features: 3 (for pizza, steak, sushi)\n",
        "\n",
        "**Your Task:**\n",
        "1.  Implement the `LeNet` class following the architecture above.\n",
        "2.  Instantiate the model and move it to the `device` (GPU/CPU).\n",
        "3.  Define the loss function (`nn.CrossEntropyLoss`) and optimizer (`optim.Adam`).\n",
        "4.  Train the LeNet model for a few epochs (e.g., 5-10).\n",
        "5.  Evaluate its performance on the test set."
      ],
      "metadata": {
        "id": "mz24H8yLd7Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Calculate the flattened size: 16 * 53 * 53\n",
        "        self.fc1 = nn.Linear(in_features=16 * 53 * 53, out_features=120)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 53 * 53) # Flatten the tensor\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.relu4(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "es8XVEl5a06G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model = LeNet(num_classes=3).to(device)\n",
        "\n",
        "lenet_model"
      ],
      "metadata": {
        "id": "Y1pK8roGcYEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop function (to be reused)\n",
        "def train_model(model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs):\n",
        "    print(f\"\\n--- Training {model.__class__.__name__} for {num_epochs} epochs ---\")\n",
        "    results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Training Progress\"):\n",
        "        # Training phase\n",
        "        model.train() # Set model to training mode\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in train_dataloader:\n",
        "            # Write your code here\n",
        "            # 1. Move inputs and labels to device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # 2. Zero the gradient\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 3. Make predictions\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # 4. Calculate the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 5. Calculate the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # 6. Update model's parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate total loss and accuracy\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_train_loss = train_loss / len(train_dataloader.dataset)\n",
        "        epoch_train_acc = train_correct / train_total\n",
        "        results[\"train_loss\"].append(epoch_train_loss)\n",
        "        results[\"train_acc\"].append(epoch_train_acc)\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval() # Set model to evaluation mode\n",
        "        test_loss = 0.0\n",
        "        test_correct = 0\n",
        "        test_total = 0\n",
        "        with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "            for inputs, labels in test_dataloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                test_total += labels.size(0)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_test_loss = test_loss / len(test_dataloader.dataset)\n",
        "        epoch_test_acc = test_correct / test_total\n",
        "        results[\"test_loss\"].append(epoch_test_loss)\n",
        "        results[\"test_acc\"].append(epoch_test_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f} | \"\n",
        "              f\"Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.4f}\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "ok-F447nVwL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lenet_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "WcSAoCi4oB5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the LeNet model\n",
        "lenet_results = train_model(lenet_model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs=10)"
      ],
      "metadata": {
        "id": "q_li-wN3lTB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(lenet_results['train_loss'], label='Train Loss')\n",
        "plt.plot(lenet_results['test_loss'], label='Test Loss')\n",
        "plt.title('LeNet Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(lenet_results['train_acc'], label='Train Accuracy')\n",
        "plt.plot(lenet_results['test_acc'], label='Test Accuracy')\n",
        "plt.title('LeNet Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HSQQpyB_lU-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions for Part 1:\n",
        "1.  How did the LeNet model perform on the test set? What was its final test accuracy?\n",
        "    *   **Your Answer:**\n",
        "    Based on the training history plotted above, the LeNet model's final test accuracy was approximately 0.4. The model's performance on the test set improved over the first few epochs but then seemed to decrease, indicating potential overfitting to the training data. The loss also fluctuated on the test set."
      ],
      "metadata": {
        "id": "o6CXS-w7ed8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Transfer Learning\n",
        "\n",
        "Training a deep CNN from scratch can be computationally expensive and requires a large amount of data. Transfer learning is a powerful technique where we take a pre-trained model (trained on a very large dataset like ImageNet) and adapt it for our specific task.\n",
        "\n",
        "Here, we will use `EfficientNet_B0` from `torchvision.models`, which is a powerful and efficient model.\n",
        "\n",
        "[List of pretrained models in Pytorch](https://docs.pytorch.org/vision/main/models.html#classification)\n",
        "\n",
        "**Your Task:**\n",
        "1.  Load a pre-trained `EfficientNet_B0` model.\n",
        "2.  \"Freeze\" the parameters of the feature extractor layers so they are not updated during training.\n",
        "3.  Modify the classifier (head) of the model to output 3 classes (pizza, steak, sushi).\n",
        "    *   *Hint*: For `EfficientNet_B0`, the classifier is typically accessed via `model.classifier`. You'll need to replace its last layer.\n",
        "4.  Instantiate the modified model and move it to the `device`.\n",
        "5.  Define the loss function (`nn.CrossEntropyLoss`) and optimizer.\n",
        "    *   *Important*: Ensure the optimizer *only* updates the parameters of the new, unfrozen layers.\n",
        "6.  Train the transfer learning model for a few epochs (e.g., 5-10).\n",
        "7.  Evaluate its performance on the test set."
      ],
      "metadata": {
        "id": "JpAwzQUBe6Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load a pre-trained EfficientNet_B0 model\n",
        "efficientnet_model = models.efficientnet_b0(pretrained=True)"
      ],
      "metadata": {
        "id": "XWeUVDVFmgoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model"
      ],
      "metadata": {
        "id": "tpZj5cBYgfGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Freeze all parameters in the feature extractor part\n",
        "freeze_params = True\n",
        "if freeze_params:\n",
        "    for param in efficientnet_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "# 3 Change the head (the classifier) of the model\n",
        "num_ftrs = efficientnet_model.classifier[1].in_features\n",
        "efficientnet_model.classifier[1] = nn.Linear(num_ftrs, 3)\n",
        "\n",
        "\n",
        "efficientnet_model = efficientnet_model.to(device)\n",
        "print(\"\\nModified EfficientNet_B0 classifier head:\")\n",
        "print(efficientnet_model.classifier)"
      ],
      "metadata": {
        "id": "Mpycmt3NVy5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which parameters are being trained\n",
        "print(\"\\nParameters to be trained:\")\n",
        "params_to_update = []\n",
        "for name, param in efficientnet_model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(name)"
      ],
      "metadata": {
        "id": "-J2h_y-cm8Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define loss function and optimizer (only for the new parameters)\n",
        "criterion_tl = nn.CrossEntropyLoss()\n",
        "optimizer_tl = optim.Adam(efficientnet_model.classifier.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "nANDOtVMm8hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Train the transfer learning model\n",
        "efficientnet_results = train_model(efficientnet_model, train_dataloader, test_dataloader, criterion_tl, optimizer_tl, num_epochs=10)"
      ],
      "metadata": {
        "id": "LON7Fm9km8nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(efficientnet_results['train_loss'], label='Train Loss')\n",
        "plt.plot(efficientnet_results['test_loss'], label='Test Loss')\n",
        "plt.title('EfficientNet Loss (Transfer Learning)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(efficientnet_results['train_acc'], label='Train Accuracy')\n",
        "plt.plot(efficientnet_results['test_acc'], label='Test Accuracy')\n",
        "plt.title('EfficientNet Accuracy (Transfer Learning)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v1FfE526nNl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions for Part 2:\n",
        "1.  Compare the performance of the LeNet model (from Part 1) with the transfer learning model (EfficientNet_B0). Which one performed better and why do you think that is?\n",
        "    *   **Your Answer:**\n",
        "    The EfficientNet_B0 model using transfer learning performed significantly better on the test set compared to the LeNet model. EfficientNet_B0 is a much larger and more complex model pre-trained on a massive dataset (ImageNet), allowing it to learn powerful and generalizable features that are highly effective for image classification\n",
        "2.  Explain the concept of \"freezing\" layers in transfer learning. Why is it done, and what are its benefits?\n",
        "    *   **Your Answer:**\n",
        "    freezing layers prevents the weights of these layers from being updated during the training process. It is done to leverage the pre-trained knowledge embedded in these layers. The benefits include:\n",
        "      **Reduced training time:** Only a small portion of the model (the new classifier) needs to be trained.\n",
        "      **Reduced data requirements:** The pre-trained model has already learned general features, so less data is needed to train the new task.\n",
        "      **Improved performance:** The model benefits from the powerful features learned from the large dataset, leading to better performance, especially on smaller datasets.\n",
        "3.  What challenges might arise when using transfer learning on a dataset that is significantly different from the dataset the pre-trained model was originally trained on (e.g., medical images vs. ImageNet)?\n",
        "    *   **Your Answer:**\n",
        "    When the new dataset is significantly different from the one the pre-trained model was trained on (e.g., medical images vs. ImageNet), challenges can arise because the features learned by the pre-trained model might not be as relevant to the new task. The model might struggle to generalize, and the initial performance might be poor.\n",
        "4.  Choose 3 images from the test set. Display the images and show their predicted classes."
      ],
      "metadata": {
        "id": "8gyxRyRHfcOT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1dad6d6"
      },
      "source": [
        "import random\n",
        "\n",
        "test_images, test_labels = next(iter(test_dataloader))\n",
        "random_indices = random.sample(range(len(test_images)), 3)\n",
        "\n",
        "selected_images = test_images[random_indices]\n",
        "selected_labels = [class_names[test_labels[i].item()] for i in random_indices]\n",
        "\n",
        "efficientnet_model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = efficientnet_model(selected_images.to(device))\n",
        "    _, predicted_indices = torch.max(outputs, 1)\n",
        "    predicted_classes = [class_names[i.item()] for i in predicted_indices]\n",
        "\n",
        "def imshow_with_predictions(inp, titles=None):\n",
        "    \"\"\"Imshow for Tensor with titles.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.imshow(inp)\n",
        "    plt.axis('off')\n",
        "    if titles is not None:\n",
        "        num_images = len(titles)\n",
        "        img_width = inp.shape[1] // num_images\n",
        "        for i, title in enumerate(titles):\n",
        "            plt.text(i * img_width + img_width/2, inp.shape[0] + 20, title,\n",
        "                     ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "imshow_with_predictions(torchvision.utils.make_grid(selected_images),\n",
        "                        titles=[f\"True: {true}, Pred: {pred}\" for true, pred in zip(selected_labels, predicted_classes)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of making prediction on an image\n",
        "\n",
        "x = torch.rand(1, 3, 224, 224)  # an image\n",
        "\n",
        "prediction = efficientnet_model(x.to(device))\n",
        "\n",
        "torch.argmax(prediction)\n",
        "\n"
      ],
      "metadata": {
        "id": "No6lZcHCg_Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ P(y=0 | x) = \\frac{e^{0.1164}}{e^{0.1164} + e^{-0.0953} + e^{0.0978}}. $$\n",
        "\n",
        "$$ P(y=1 | x) = \\frac{e^{-0.0953}}{e^{0.1164} + e^{-0.0953} + e^{0.0978}}. $$\n",
        "\n",
        "$$ P(y=2 | x) = \\frac{e^{0.0978}}{e^{0.1164} + e^{-0.0953} + e^{0.0978}}. $$"
      ],
      "metadata": {
        "id": "JRyKAexKlWCd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}